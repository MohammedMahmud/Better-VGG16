{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mohammed_Mahmud.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "PYiuTXV51xza",
        "nmejDb0pSlc7",
        "15b9RdRfZjFu",
        "Kp4fv_QPP-Oo",
        "rUwHcq0LULo6",
        "MCYk1tl0IDc4",
        "WCKDiEeqc4sJ",
        "S1ComxA5feta",
        "_7EaMXF5zv-p",
        "pk2uIVuAT0WO",
        "dHtAcquiX8Fd",
        "R6fG_lAk1YYo",
        "PS6AZ2H-rGyT",
        "6kMsg4-GhMbI",
        "ZK5CJRdi9-VR",
        "zI6lOAEkmuxD",
        "p67mUOb4f_wr",
        "KfbtfsmOi60D",
        "zAs4aWaCjTyI",
        "USUgtd_jdeSD",
        "5Ycl-2gXdzZe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "PYiuTXV51xza",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Importing Everything (Necessary Libraries)**"
      ]
    },
    {
      "metadata": {
        "id": "eIIOQB3UIaqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# importing Everything\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "import datetime\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nmejDb0pSlc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Mounting To Google Drive**"
      ]
    },
    {
      "metadata": {
        "id": "lENdGBcDNaYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "! ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15b9RdRfZjFu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create The Symbolic Link **"
      ]
    },
    {
      "metadata": {
        "id": "EH6Xfaa4O0n_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls\n",
        "! ln -s /content/drive/'My Drive'/hello "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kp4fv_QPP-Oo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Checking Symbolic Link Works or Not**"
      ]
    },
    {
      "metadata": {
        "id": "ulUIJH6WRd27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls hello"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6PYqub-E2L30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **CUDA, Models , Loss function and Hyperparameter Optimizer.**"
      ]
    },
    {
      "metadata": {
        "id": "42Uq-r4wJIXa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Calling_Cuda ():\n",
        "    # Is GPU Available or Na?\n",
        "    GPU_available = torch.cuda.is_available()\n",
        "    \n",
        "    # shows the GPU Type\n",
        "    GPU_type = torch.cuda.get_device_name(0)\n",
        "    \n",
        "    # shows how many GPU are ther\n",
        "    How_Many_GPU = torch.cuda.device_count()\n",
        "    \n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    if use_gpu:\n",
        "        print(\"Using CUDA\")\n",
        "    \n",
        "    what_device = torch.device(type='cuda')\n",
        "    \n",
        "    # Printing info\n",
        "    print(GPU_available, \"\\n\", GPU_type, \"\\n\", How_Many_GPU, \"\\n\", what_device)\n",
        "    \n",
        "    # Gput info\n",
        "    !nvidia - smi\n",
        "    \n",
        "    # Pushing Everything to CUDA.\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # printing CUDA available or cpu\n",
        "    print(device)\n",
        "    \n",
        "    # Downloading pre-trained vgg16 models.\n",
        "    vgg16_model = models.vgg16(pretrained=True)\n",
        "    # Pushing vgg16 pre-trained models to CUDA.\n",
        "    vgg16_model = vgg16_model.to(device)\n",
        "    \n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Hyperparameter optimizer -- for the Nonlinearity function--\n",
        "    optimizer = optim.SGD(vgg16_model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUwHcq0LULo6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ** Preparing Train & Validation Sets**"
      ]
    },
    {
      "metadata": {
        "id": "d3f-zXHk_2cu",
        "colab_type": "code",
        "outputId": "4040900f-ad94-4385-d030-b85f2ede504d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "\n",
        "# This is from GitHub...I just tweaked couple things...\n",
        "# augment will be True\n",
        "def get_train_valid_loader(augment, valid_size=0.2, shuffle=True, num_workers=0, pin_memory=True):\n",
        "    \n",
        "    # Picks a random number/Vector \n",
        "    random_seed = random.seed(9001)\n",
        "  \n",
        "    # Don't want High or Low numbers - Samples are wide range - Normalize Needed\n",
        "    # problem normalize doesn't exist -- Exploding gradien.    \n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],)\n",
        "    \n",
        "    # Define transforms\n",
        "    # Ensuring that our model is not overfitting or under fitting.\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "   \n",
        "    # augment = True : This one always running     \n",
        "    if augment:\n",
        "        # Resizing the image, Random Horizontal Flip, and normalize \n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    # Load the dataset\n",
        "    # train_dataset -- 50000\n",
        "    # valid_dataset -- 50000\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform,)\n",
        "    valid_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=valid_transform,)\n",
        "    \n",
        "    # num_train = 50000\n",
        "    num_train = len(train_dataset)\n",
        "\n",
        "    # Empty Array/List of 50000\n",
        "    indices = list(range(num_train))\n",
        "    \n",
        "    # Rounded values: (20% * 50000) = 10,000\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "  \n",
        "    # shuffle = True : This one always running   \n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        # LIST OF random NUMBER          \n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=train_sampler,\n",
        "                                                num_workers=num_workers, pin_memory=pin_memory,)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, sampler=valid_sampler,\n",
        "                                               num_workers=num_workers, pin_memory=pin_memory,)\n",
        "    \n",
        "    # returning test set and validation set as tuple\n",
        "    return (train_loader, valid_loader)\n",
        "  \n",
        "# QUICK MATH\n",
        "# --------------------------------------\n",
        "# 40,000 Image's For Train --- 63.34%\n",
        "# 10,000 Image's For Validation --- 20%\n",
        "# 10,000 Image's For Test --- 16.66%\n",
        "# --------------------------------------\n",
        "# 40,000(Images) / 32(batch_size(parallel)) = 1,250 (Each Epoch Batch)\n",
        "# 1250(Each batch) Ã— 32(batch_size) = 40,000 \n",
        "# 11% Difference\n",
        "\n",
        "the_train_loader, the_valid_loader = get_train_valid_loader(True)\n",
        "# checking --- printing the size \n",
        "print(len(the_train_loader))\n",
        "print(len(the_valid_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n",
            "1250\n",
            "313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MCYk1tl0IDc4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Preparing Test Set**"
      ]
    },
    {
      "metadata": {
        "id": "H_1ClVhH-wTA",
        "colab_type": "code",
        "outputId": "7c98694a-092c-400f-8d21-71e58fad975d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "def get_test_loader(batch_size=32, shuffle=True, num_workers=0, pin_memory=True):\n",
        "\n",
        "    normalize = transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],)\n",
        "\n",
        "    # define transform\n",
        "    transform = transforms.Compose([ transforms.Resize(224),transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize,])\n",
        "    \n",
        "\n",
        "    dataset = datasets.CIFAR10(root='./data', train=False,download=True, transform=transform,)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory,)\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "the_test_loader = get_test_loader()\n",
        "print(len(the_test_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WCKDiEeqc4sJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Checking Downloaded File is Available or No?**"
      ]
    },
    {
      "metadata": {
        "id": "-u9WWkpvGDvJ",
        "colab_type": "code",
        "outputId": "a9f7d9a3-7d89-471a-e85a-5a25b5a63f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        }
      },
      "cell_type": "code",
      "source": [
        "# checking is the file is available or na???\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  drive  hello  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S1ComxA5feta",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **See The Model Visually**"
      ]
    },
    {
      "metadata": {
        "id": "YFDDTfRo0OEj",
        "colab_type": "code",
        "outputId": "3bc55a40-7e8e-46d5-f182-45d6c8e8069e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "cell_type": "code",
      "source": [
        "# PRINT THE model to see visually\n",
        "print(vgg16_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_7EaMXF5zv-p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Freezing up all the layers &  Unfreeze Layer 6 --- Classifier (1)**\n",
        "Train the network with all but the classification layer frozen"
      ]
    },
    {
      "metadata": {
        "id": "GhAaprcZQYy3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def FreezingUp_ONE():\n",
        "    # Freezing up all the layers\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Freezing up all the classifier\n",
        "    for param in vgg16_model.classifier.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze Layer 6 --- Classifier\n",
        "    for param in vgg16_model.classifier[6].parameters():\n",
        "        param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pk2uIVuAT0WO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Only The Last Two Fully Connected Layers Frozen (2)**"
      ]
    },
    {
      "metadata": {
        "id": "xl78chRBTzUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def FreezingUp_TWO():\n",
        "    # Freezing up all the layers\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Freezing up all the classifier\n",
        "    for param in vgg16_model.classifier.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Unfreeze Layer 3 --- Classifier\n",
        "    for param in vgg16_model.classifier[3].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Unfreeze Layer 6 --- Classifier\n",
        "    for param in vgg16_model.classifier[6].parameters():\n",
        "        param.requires_grad = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHtAcquiX8Fd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Last Convolution Layer &  Last Two Fully Connected Layers Frozen (3)**"
      ]
    },
    {
      "metadata": {
        "id": "pOJkmQCmYDZ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def FreezingUp_THREE():\n",
        "    # Freezing up all the layers\n",
        "    for param in vgg16_model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Freezing up all the classifier\n",
        "    for param in vgg16_model.classifier.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Unfreeze up all the layers\n",
        "    for param in vgg16_model.features[28].parameters():\n",
        "        param.requires_grad = True\n",
        "        \n",
        "    # Unfreeze Layer 3 --- Classifier\n",
        "    for param in vgg16_model.classifier[3].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Unfreeze Layer 6 --- Classifier\n",
        "    for param in vgg16_model.classifier[6].parameters():\n",
        "        param.requires_grad = True\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6fG_lAk1YYo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Train The Network**"
      ]
    },
    {
      "metadata": {
        "id": "ICMphE_PAKNH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def modal_call(the_data_loader,epoch_size):\n",
        "    # Start Time\n",
        "    start_time = datetime.datetime.now()    \n",
        "    # Finding Accuracy\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    class_correct = list(0. for x in range(10))\n",
        "    class_total = list(0. for y in range(10))\n",
        "    \n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    for epoch in range(epoch_size):  # Loop Over The Data-set  Multiple Times\n",
        "        print('Epoch: ', epoch)\n",
        "        running_loss = 0.0\n",
        "    \n",
        "        each_Epoch_time_START = datetime.datetime.now()\n",
        "        # Iterate Over Data.\n",
        "        for i, (inputs, labels) in enumerate(the_data_loader):\n",
        "            # Get the inputs\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "    \n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "    \n",
        "            # Forward + backward + optimize\n",
        "            outputs = vgg16_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "            # Printing Statistics\n",
        "            running_loss += loss.item()\n",
        "    \n",
        "            if i % 250 == 249:  # Print Every 250 (Mini-Batches)\n",
        "                print('[%d, %5d] Loss: %.3f' % (epoch + 1, i + 1, running_loss / (i + 1)))\n",
        "    \n",
        "            # Finding Accuracy the %\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            c = (preds == labels).squeeze()\n",
        "    \n",
        "            _, preds2 = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds2 == labels).sum().item()\n",
        "    \n",
        "        # Printing Statistics\n",
        "        print(\"Epoch: \", epoch, \" Loss: %.3f\" % (running_loss / 1250), \" Accuracy: %.2f\" % (100 * correct/total), \"%\")\n",
        "        each_Epoch_time_DONE = datetime.datetime.now()\n",
        "        each_Epoch_whole_time = each_Epoch_time_DONE - each_Epoch_time_START\n",
        "        print(\"Epoch: \", epoch, \"It Takes: \", each_Epoch_whole_time, \" Minutes\")\n",
        "    \n",
        "        # running_loss_two = 0.0\n",
        "        torch.save(vgg16_model.state_dict(), \"hello/model_{0:03d}.pth\".format(epoch))\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    end_time = datetime.datetime.now()\n",
        "    the_whole_time = end_time - start_time\n",
        "    print('Finished Training -- The Whole Time Is: \\t', the_whole_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PS6AZ2H-rGyT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Test The Network On The Test Data**"
      ]
    },
    {
      "metadata": {
        "id": "raDW0PayrNtH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Test_The_Network():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in the_test_loader:\n",
        "            images, labels = data\n",
        "    \n",
        "            # Send it to CUDA\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "    \n",
        "            outputs = vgg16_model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kMsg4-GhMbI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix**"
      ]
    },
    {
      "metadata": {
        "id": "Ue18qkJwiCcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Confusion_Matrix():\n",
        "    Matrix = [[0 for x in range(10)] for y in range(10)]\n",
        "    with torch.no_grad():\n",
        "        for data in the_test_loader:\n",
        "            images, labels = data\n",
        "            \n",
        "            # Send it to CUDA\n",
        "            images = images.to(device) \n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Model at that time     \n",
        "            outputs = vgg16_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            # 10,016 images tahats why its len()\n",
        "            for i in range(len(labels)):\n",
        "                # ground_truth and pred ands up 1 everytime\n",
        "                ground_truth = labels[i]\n",
        "                pred = predicted[i]\n",
        "                Matrix[ground_truth][pred] += 1\n",
        "                \n",
        "    return Matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZK5CJRdi9-VR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Classes Perform Accuracy**"
      ]
    },
    {
      "metadata": {
        "id": "1S4cx2ZX93ZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Classes_Perform_Accuracy():\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    with torch.no_grad():\n",
        "        for data in the_test_loader:\n",
        "            images, labels = data\n",
        "    \n",
        "            # Get the inputs\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "    \n",
        "            outputs = vgg16_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(4):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "    \n",
        "    for i in range(10):\n",
        "        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zI6lOAEkmuxD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Result: Training and Testing Network(1) ** \n",
        "Train the network with all but the classification layer frozen"
      ]
    },
    {
      "metadata": {
        "id": "DtSm9gGSXZXp",
        "colab_type": "code",
        "outputId": "857ee4f9-aae1-4a0c-f860-b13f9ef23be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2006
        }
      },
      "cell_type": "code",
      "source": [
        "def classification_TASK_ONE():\n",
        "    Calling_Cuda()\n",
        "    print(\"\\n\")\n",
        "    print(\"(i) Train the network with all but the classification layer frozen\")\n",
        "    print(\"________________________________________________________________\")\n",
        "    # Frozen layer\n",
        "    FreezingUp_ONE()\n",
        "    print(\"Training\")\n",
        "    print(\"---------\")\n",
        "    print(modal_call(the_train_loader,1))\n",
        "    print(\"\\n\")\n",
        "    print(\"Testing\")\n",
        "    print(\"--------\")\n",
        "    print(Test_The_Network())\n",
        "    print(\"\\n\")\n",
        "    print(\"Confusion Matrix\")\n",
        "    pritn(Confusion_Matrix())\n",
        "    print(\"------------------\")\n",
        "    print(\"\\n\")\n",
        "    print(\"Classes Perform Accuracy\")\n",
        "    print(\"---------------------------\")\n",
        "    print(Classes_Perform_Accuracy())\n",
        "    print(\"\\n DONE \\n\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "---------\n",
            "Epoch:  0\n",
            "[1,   250] Loss: 1.946\n",
            "[1,   500] Loss: 1.353\n",
            "[1,   750] Loss: 1.147\n",
            "[1,  1000] Loss: 1.030\n",
            "[1,  1250] Loss: 0.955\n",
            "Epoch:  0  Loss: 0.955  Accuracy: 71.65 %\n",
            "Epoch:  0 It Takes:  0:11:21.887737  Minutes\n",
            "\n",
            "\n",
            "Epoch:  1\n",
            "[2,   250] Loss: 0.640\n",
            "[2,   500] Loss: 0.638\n",
            "[2,   750] Loss: 0.637\n",
            "[2,  1000] Loss: 0.632\n",
            "[2,  1250] Loss: 0.632\n",
            "Epoch:  1  Loss: 0.632  Accuracy: 74.81 %\n",
            "Epoch:  1 It Takes:  0:11:21.351522  Minutes\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "[3,   250] Loss: 0.601\n",
            "[3,   500] Loss: 0.605\n",
            "[3,   750] Loss: 0.606\n",
            "[3,  1000] Loss: 0.607\n",
            "[3,  1250] Loss: 0.606\n",
            "Epoch:  2  Loss: 0.606  Accuracy: 76.09 %\n",
            "Epoch:  2 It Takes:  0:11:22.535176  Minutes\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "[4,   250] Loss: 0.587\n",
            "[4,   500] Loss: 0.585\n",
            "[4,   750] Loss: 0.590\n",
            "[4,  1000] Loss: 0.592\n",
            "[4,  1250] Loss: 0.594\n",
            "Epoch:  3  Loss: 0.594  Accuracy: 76.89 %\n",
            "Epoch:  3 It Takes:  0:11:22.733712  Minutes\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "[5,   250] Loss: 0.584\n",
            "[5,   500] Loss: 0.589\n",
            "[5,   750] Loss: 0.582\n",
            "[5,  1000] Loss: 0.581\n",
            "[5,  1250] Loss: 0.582\n",
            "Epoch:  4  Loss: 0.582  Accuracy: 77.37 %\n",
            "Epoch:  4 It Takes:  0:11:21.681940  Minutes\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "[6,   250] Loss: 0.557\n",
            "[6,   500] Loss: 0.569\n",
            "[6,   750] Loss: 0.574\n",
            "[6,  1000] Loss: 0.572\n",
            "[6,  1250] Loss: 0.571\n",
            "Epoch:  5  Loss: 0.571  Accuracy: 77.79 %\n",
            "Epoch:  5 It Takes:  0:11:24.061182  Minutes\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "[7,   250] Loss: 0.561\n",
            "[7,   500] Loss: 0.566\n",
            "[7,   750] Loss: 0.564\n",
            "[7,  1000] Loss: 0.565\n",
            "[7,  1250] Loss: 0.567\n",
            "Epoch:  6  Loss: 0.567  Accuracy: 78.09 %\n",
            "Epoch:  6 It Takes:  0:11:23.179538  Minutes\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "[8,   250] Loss: 0.564\n",
            "[8,   500] Loss: 0.570\n",
            "[8,   750] Loss: 0.564\n",
            "[8,  1000] Loss: 0.564\n",
            "[8,  1250] Loss: 0.564\n",
            "Epoch:  7  Loss: 0.564  Accuracy: 78.35 %\n",
            "Epoch:  7 It Takes:  0:11:23.662518  Minutes\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "[9,   250] Loss: 0.542\n",
            "[9,   500] Loss: 0.550\n",
            "[9,   750] Loss: 0.556\n",
            "[9,  1000] Loss: 0.557\n",
            "[9,  1250] Loss: 0.557\n",
            "Epoch:  8  Loss: 0.557  Accuracy: 78.58 %\n",
            "Epoch:  8 It Takes:  0:11:25.029669  Minutes\n",
            "\n",
            "\n",
            "Finished Training -- The Whole Time Is: \t 1:42:53.605738\n",
            "None\n",
            "\n",
            "\n",
            "Testing\n",
            "--------\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "None\n",
            "\n",
            "\n",
            "Classes Perform Accuracy\n",
            "---------------------------\n",
            "Accuracy of plane : 71 %\n",
            "Accuracy of   car : 86 %\n",
            "Accuracy of  bird : 72 %\n",
            "Accuracy of   cat : 65 %\n",
            "Accuracy of  deer : 83 %\n",
            "Accuracy of   dog : 74 %\n",
            "Accuracy of  frog : 75 %\n",
            "Accuracy of horse : 87 %\n",
            "Accuracy of  ship : 94 %\n",
            "Accuracy of truck : 80 %\n",
            "None\n",
            "\n",
            " DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p67mUOb4f_wr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Result: Training and Testing Network(2) ** \n",
        "Train the network with all but only the last two fully connected layers frozen"
      ]
    },
    {
      "metadata": {
        "id": "Qj-m3-zogctD",
        "colab_type": "code",
        "outputId": "e548b7c6-2fb8-4395-de2b-cdce705803b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2703
        }
      },
      "cell_type": "code",
      "source": [
        "def classification_TASK_TWO():\n",
        "    Calling_Cuda()\n",
        "    print(\"\\n\")\n",
        "    print(\"(ii) Train the network with all but only the last two fully connected layers frozen\")\n",
        "    print(\"________________________________________________________________\")\n",
        "    FreezingUp_TWO()\n",
        "    print(\"Training\")\n",
        "    print(\"---------\")\n",
        "    print(modal_call(the_train_loader,1))\n",
        "    print(\"\\n\")\n",
        "    print(\"Testing\")\n",
        "    print(\"--------\")\n",
        "    print(Test_The_Network())\n",
        "    print(\"\\n\")\n",
        "    print(\"Confusion Matrix\")\n",
        "    print(Confusion_Matrix())\n",
        "    print(\"------------------\")\n",
        "    print(\"\\n\")\n",
        "    print(\"Classes Perform Accuracy\")\n",
        "    print(\"---------------------------\")\n",
        "    print(Classes_Perform_Accuracy())\n",
        "    print(\"\\n DONE \\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "---------\n",
            "Epoch:  0\n",
            "[1,   250] Loss: 1.685\n",
            "[1,   500] Loss: 1.209\n",
            "[1,   750] Loss: 1.030\n",
            "[1,  1000] Loss: 0.931\n",
            "[1,  1250] Loss: 0.868\n",
            "Epoch:  0  Loss: 0.868  Accuracy: 73.30 %\n",
            "Epoch:  0 It Takes:  0:10:38.295604  Minutes\n",
            "\n",
            "\n",
            "Epoch:  1\n",
            "[2,   250] Loss: 0.580\n",
            "[2,   500] Loss: 0.571\n",
            "[2,   750] Loss: 0.564\n",
            "[2,  1000] Loss: 0.563\n",
            "[2,  1250] Loss: 0.557\n",
            "Epoch:  1  Loss: 0.557  Accuracy: 76.91 %\n",
            "Epoch:  1 It Takes:  0:10:35.794635  Minutes\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "[3,   250] Loss: 0.514\n",
            "[3,   500] Loss: 0.513\n",
            "[3,   750] Loss: 0.516\n",
            "[3,  1000] Loss: 0.510\n",
            "[3,  1250] Loss: 0.512\n",
            "Epoch:  2  Loss: 0.512  Accuracy: 78.65 %\n",
            "Epoch:  2 It Takes:  0:10:35.205661  Minutes\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "[4,   250] Loss: 0.503\n",
            "[4,   500] Loss: 0.487\n",
            "[4,   750] Loss: 0.480\n",
            "[4,  1000] Loss: 0.480\n",
            "[4,  1250] Loss: 0.482\n",
            "Epoch:  3  Loss: 0.482  Accuracy: 79.80 %\n",
            "Epoch:  3 It Takes:  0:10:35.370932  Minutes\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "[5,   250] Loss: 0.452\n",
            "[5,   500] Loss: 0.459\n",
            "[5,   750] Loss: 0.459\n",
            "[5,  1000] Loss: 0.456\n",
            "[5,  1250] Loss: 0.457\n",
            "Epoch:  4  Loss: 0.457  Accuracy: 80.63 %\n",
            "Epoch:  4 It Takes:  0:10:35.356521  Minutes\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "[6,   250] Loss: 0.437\n",
            "[6,   500] Loss: 0.430\n",
            "[6,   750] Loss: 0.431\n",
            "[6,  1000] Loss: 0.432\n",
            "[6,  1250] Loss: 0.435\n",
            "Epoch:  5  Loss: 0.435  Accuracy: 81.28 %\n",
            "Epoch:  5 It Takes:  0:10:35.224889  Minutes\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "[7,   250] Loss: 0.425\n",
            "[7,   500] Loss: 0.422\n",
            "[7,   750] Loss: 0.418\n",
            "[7,  1000] Loss: 0.419\n",
            "[7,  1250] Loss: 0.420\n",
            "Epoch:  6  Loss: 0.420  Accuracy: 81.84 %\n",
            "Epoch:  6 It Takes:  0:10:35.799935  Minutes\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "[8,   250] Loss: 0.392\n",
            "[8,   500] Loss: 0.399\n",
            "[8,   750] Loss: 0.403\n",
            "[8,  1000] Loss: 0.401\n",
            "[8,  1250] Loss: 0.400\n",
            "Epoch:  7  Loss: 0.400  Accuracy: 82.36 %\n",
            "Epoch:  7 It Takes:  0:10:35.102559  Minutes\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "[9,   250] Loss: 0.377\n",
            "[9,   500] Loss: 0.378\n",
            "[9,   750] Loss: 0.382\n",
            "[9,  1000] Loss: 0.386\n",
            "[9,  1250] Loss: 0.391\n",
            "Epoch:  8  Loss: 0.391  Accuracy: 82.80 %\n",
            "Epoch:  8 It Takes:  0:10:35.475007  Minutes\n",
            "\n",
            "\n",
            "Epoch:  9\n",
            "[10,   250] Loss: 0.371\n",
            "[10,   500] Loss: 0.378\n",
            "[10,   750] Loss: 0.380\n",
            "[10,  1000] Loss: 0.377\n",
            "[10,  1250] Loss: 0.377\n",
            "Epoch:  9  Loss: 0.377  Accuracy: 83.20 %\n",
            "Epoch:  9 It Takes:  0:10:35.393408  Minutes\n",
            "\n",
            "\n",
            "Epoch:  10\n",
            "[11,   250] Loss: 0.359\n",
            "[11,   500] Loss: 0.358\n",
            "[11,   750] Loss: 0.361\n",
            "[11,  1000] Loss: 0.366\n",
            "[11,  1250] Loss: 0.366\n",
            "Epoch:  10  Loss: 0.366  Accuracy: 83.53 %\n",
            "Epoch:  10 It Takes:  0:10:38.696217  Minutes\n",
            "\n",
            "\n",
            "Epoch:  11\n",
            "[12,   250] Loss: 0.361\n",
            "[12,   500] Loss: 0.357\n",
            "[12,   750] Loss: 0.357\n",
            "[12,  1000] Loss: 0.356\n",
            "[12,  1250] Loss: 0.359\n",
            "Epoch:  11  Loss: 0.359  Accuracy: 83.84 %\n",
            "Epoch:  11 It Takes:  0:10:37.238688  Minutes\n",
            "\n",
            "\n",
            "Epoch:  12\n",
            "[13,   250] Loss: 0.331\n",
            "[13,   500] Loss: 0.344\n",
            "[13,   750] Loss: 0.344\n",
            "[13,  1000] Loss: 0.346\n",
            "[13,  1250] Loss: 0.348\n",
            "Epoch:  12  Loss: 0.348  Accuracy: 84.16 %\n",
            "Epoch:  12 It Takes:  0:10:35.956293  Minutes\n",
            "\n",
            "\n",
            "Finished Training -- The Whole Time Is: \t 2:18:32.352936\n",
            "None\n",
            "\n",
            "\n",
            "Testing\n",
            "--------\n",
            "Accuracy of the network on the 10000 test images: 84 %\n",
            "None\n",
            "\n",
            "\n",
            "Classes Perform Accuracy\n",
            "---------------------------\n",
            "Accuracy of plane : 84 %\n",
            "Accuracy of   car : 86 %\n",
            "Accuracy of  bird : 75 %\n",
            "Accuracy of   cat : 80 %\n",
            "Accuracy of  deer : 83 %\n",
            "Accuracy of   dog : 78 %\n",
            "Accuracy of  frog : 84 %\n",
            "Accuracy of horse : 82 %\n",
            "Accuracy of  ship : 88 %\n",
            "Accuracy of truck : 90 %\n",
            "None\n",
            "\n",
            " DONE \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KfbtfsmOi60D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Result: Training and Testing Network(3) ** \n",
        "Train the network with all but the last convolution layer and the last two fully connected layers frozen"
      ]
    },
    {
      "metadata": {
        "id": "SizvGh89jGLd",
        "colab_type": "code",
        "outputId": "e1aec55b-6bb7-46e6-8786-bf5eb36ffece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2873
        }
      },
      "cell_type": "code",
      "source": [
        "def classification_TASK_THREE():\n",
        "    Calling_Cuda()\n",
        "    print(\"\\n\")\n",
        "    print(\"(ii) Train the network with all but only the last two fully connected layers frozen\")\n",
        "    print(\"________________________________________________________________\")\n",
        "    FreezingUp_THREE()\n",
        "    print(\"Training\")\n",
        "    print(\"---------\")\n",
        "    print(modal_call(the_train_loader,1))\n",
        "    print(\"\\n\")\n",
        "    print(\"Testing\")\n",
        "    print(\"--------\")\n",
        "    print(Test_The_Network())\n",
        "    print(\"\\n\")\n",
        "    print(\"Confusion Matrix\")\n",
        "    print(Confusion_Matrix())\n",
        "    print(\"------------------\")\n",
        "    print(\"\\n\")\n",
        "    print(\"Classes Perform Accuracy\")\n",
        "    print(\"---------------------------\")\n",
        "    print(Classes_Perform_Accuracy())\n",
        "    print(\"\\n DONE \\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "---------\n",
            "Epoch:  0\n",
            "[1,   250] Loss: 0.330\n",
            "[1,   500] Loss: 0.324\n",
            "[1,   750] Loss: 0.323\n",
            "[1,  1000] Loss: 0.326\n",
            "[1,  1250] Loss: 0.325\n",
            "Epoch:  0  Loss: 0.325  Accuracy: 88.64 %\n",
            "Epoch:  0 It Takes:  0:11:06.785407  Minutes\n",
            "\n",
            "\n",
            "Epoch:  1\n",
            "[2,   250] Loss: 0.265\n",
            "[2,   500] Loss: 0.273\n",
            "[2,   750] Loss: 0.275\n",
            "[2,  1000] Loss: 0.277\n",
            "[2,  1250] Loss: 0.278\n",
            "Epoch:  1  Loss: 0.278  Accuracy: 89.39 %\n",
            "Epoch:  1 It Takes:  0:11:10.065793  Minutes\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "[3,   250] Loss: 0.242\n",
            "[3,   500] Loss: 0.242\n",
            "[3,   750] Loss: 0.244\n",
            "[3,  1000] Loss: 0.245\n",
            "[3,  1250] Loss: 0.245\n",
            "Epoch:  2  Loss: 0.245  Accuracy: 90.06 %\n",
            "Epoch:  2 It Takes:  0:11:07.409041  Minutes\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "[4,   250] Loss: 0.225\n",
            "[4,   500] Loss: 0.222\n",
            "[4,   750] Loss: 0.221\n",
            "[4,  1000] Loss: 0.220\n",
            "[4,  1250] Loss: 0.220\n",
            "Epoch:  3  Loss: 0.220  Accuracy: 90.64 %\n",
            "Epoch:  3 It Takes:  0:11:12.299587  Minutes\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "[5,   250] Loss: 0.211\n",
            "[5,   500] Loss: 0.203\n",
            "[5,   750] Loss: 0.202\n",
            "[5,  1000] Loss: 0.203\n",
            "[5,  1250] Loss: 0.204\n",
            "Epoch:  4  Loss: 0.204  Accuracy: 91.06 %\n",
            "Epoch:  4 It Takes:  0:11:15.678978  Minutes\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "[6,   250] Loss: 0.182\n",
            "[6,   500] Loss: 0.184\n",
            "[6,   750] Loss: 0.184\n",
            "[6,  1000] Loss: 0.185\n",
            "[6,  1250] Loss: 0.187\n",
            "Epoch:  5  Loss: 0.187  Accuracy: 91.48 %\n",
            "Epoch:  5 It Takes:  0:11:15.524875  Minutes\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "[7,   250] Loss: 0.172\n",
            "[7,   500] Loss: 0.173\n",
            "[7,   750] Loss: 0.171\n",
            "[7,  1000] Loss: 0.169\n",
            "[7,  1250] Loss: 0.169\n",
            "Epoch:  6  Loss: 0.169  Accuracy: 91.83 %\n",
            "Epoch:  6 It Takes:  0:11:15.584539  Minutes\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "[8,   250] Loss: 0.156\n",
            "[8,   500] Loss: 0.155\n",
            "[8,   750] Loss: 0.155\n",
            "[8,  1000] Loss: 0.158\n",
            "[8,  1250] Loss: 0.160\n",
            "Epoch:  7  Loss: 0.160  Accuracy: 92.16 %\n",
            "Epoch:  7 It Takes:  0:11:15.720371  Minutes\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "[9,   250] Loss: 0.137\n",
            "[9,   500] Loss: 0.136\n",
            "[9,   750] Loss: 0.139\n",
            "[9,  1000] Loss: 0.142\n",
            "[9,  1250] Loss: 0.144\n",
            "Epoch:  8  Loss: 0.144  Accuracy: 92.46 %\n",
            "Epoch:  8 It Takes:  0:11:15.202824  Minutes\n",
            "\n",
            "\n",
            "Epoch:  9\n",
            "[10,   250] Loss: 0.133\n",
            "[10,   500] Loss: 0.139\n",
            "[10,   750] Loss: 0.137\n",
            "[10,  1000] Loss: 0.137\n",
            "[10,  1250] Loss: 0.137\n",
            "Epoch:  9  Loss: 0.137  Accuracy: 92.73 %\n",
            "Epoch:  9 It Takes:  0:11:12.309043  Minutes\n",
            "\n",
            "\n",
            "Epoch:  10\n",
            "[11,   250] Loss: 0.123\n",
            "[11,   500] Loss: 0.119\n",
            "[11,   750] Loss: 0.123\n",
            "[11,  1000] Loss: 0.123\n",
            "[11,  1250] Loss: 0.124\n",
            "Epoch:  10  Loss: 0.124  Accuracy: 93.00 %\n",
            "Epoch:  10 It Takes:  0:11:15.954612  Minutes\n",
            "\n",
            "\n",
            "Epoch:  11\n",
            "[12,   250] Loss: 0.108\n",
            "[12,   500] Loss: 0.113\n",
            "[12,   750] Loss: 0.115\n",
            "[12,  1000] Loss: 0.117\n",
            "[12,  1250] Loss: 0.116\n",
            "Epoch:  11  Loss: 0.116  Accuracy: 93.25 %\n",
            "Epoch:  11 It Takes:  0:11:15.958761  Minutes\n",
            "\n",
            "\n",
            "Epoch:  12\n",
            "[13,   250] Loss: 0.106\n",
            "[13,   500] Loss: 0.106\n",
            "[13,   750] Loss: 0.107\n",
            "[13,  1000] Loss: 0.106\n",
            "[13,  1250] Loss: 0.107\n",
            "Epoch:  12  Loss: 0.107  Accuracy: 93.48 %\n",
            "Epoch:  12 It Takes:  0:11:15.914571  Minutes\n",
            "\n",
            "\n",
            "Epoch:  13\n",
            "[14,   250] Loss: 0.095\n",
            "[14,   500] Loss: 0.097\n",
            "[14,   750] Loss: 0.098\n",
            "[14,  1000] Loss: 0.099\n",
            "[14,  1250] Loss: 0.100\n",
            "Epoch:  13  Loss: 0.100  Accuracy: 93.70 %\n",
            "Epoch:  13 It Takes:  0:11:14.893174  Minutes\n",
            "\n",
            "\n",
            "Finished Training -- The Whole Time Is: \t 2:37:52.697674\n",
            "None\n",
            "\n",
            "\n",
            "Testing\n",
            "--------\n",
            "Accuracy of the network on the 10000 test images: 88 %\n",
            "None\n",
            "\n",
            "\n",
            "Classes Perform Accuracy\n",
            "---------------------------\n",
            "Accuracy of plane : 92 %\n",
            "Accuracy of   car : 94 %\n",
            "Accuracy of  bird : 87 %\n",
            "Accuracy of   cat : 83 %\n",
            "Accuracy of  deer : 80 %\n",
            "Accuracy of   dog : 83 %\n",
            "Accuracy of  frog : 87 %\n",
            "Accuracy of horse : 84 %\n",
            "Accuracy of  ship : 95 %\n",
            "Accuracy of truck : 91 %\n",
            "None\n",
            "\n",
            " DONE \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzYcULF1zruY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Calling All Autobots**"
      ]
    },
    {
      "metadata": {
        "id": "AjElLad3zoyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classification_TASK_ONE()\n",
        "classification_TASK_TWO()\n",
        "classification_TASK_THREE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAs4aWaCjTyI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Show Images**"
      ]
    },
    {
      "metadata": {
        "id": "iq_kdnrxjgyA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_images(images, cls_true, cls_pred=None):\n",
        "    \"\"\"\n",
        "    Adapted from https://github.com/Hvass-Labs/TensorFlow-Tutorials/\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(3, 3)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # plot img\n",
        "        ax.imshow(images[i, :, :, :], interpolation='spline16')\n",
        "\n",
        "        # show true & predicted classes\n",
        "        cls_true_name = label_names[cls_true[i]]\n",
        "        if cls_pred is None:\n",
        "            xlabel = \"{0} ({1})\".format(cls_true_name, cls_true[i])\n",
        "        else:\n",
        "            cls_pred_name = label_names[cls_pred[i]]\n",
        "            xlabel = \"True: {0}\\nPred: {1}\".format(\n",
        "                cls_true_name, cls_pred_name\n",
        "            )\n",
        "        ax.set_xlabel(xlabel)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USUgtd_jdeSD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Checked Model Saved or Not!!!!**"
      ]
    },
    {
      "metadata": {
        "id": "OxQesgk4bYhG",
        "colab_type": "code",
        "outputId": "a4a44924-76dc-4f16-c1ab-31cbdbdf1c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "cell_type": "code",
      "source": [
        "! pwd\n",
        "! ls hello"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Ycl-2gXdzZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading up the **Model** "
      ]
    },
    {
      "metadata": {
        "id": "o8N_6kGPZfOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = torch.load('hello/model_005.pth')\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}